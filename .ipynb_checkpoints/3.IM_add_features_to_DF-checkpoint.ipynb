{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add features to the DF\n",
    "* This notebook contains code that calculates the graph-based feature values.\n",
    "* It demonstrates values on Britannica.\n",
    "* It demonstrates statistically significant differences on both Britannica and Newsela.\n",
    "* The files britannica/newsela/britannica_semrel/britannica_sematch_with_features.csv in the csv folder were created with this notebook.\n",
    "* The last section contains outlier removal based on the exclusivity-based semantic relatedness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "from collections import defaultdict\n",
    "import itertools\n",
    "import networkx\n",
    "from networkx.algorithms import average_clustering\n",
    "from networkx.algorithms.cluster import clustering\n",
    "from networkx.algorithms import shortest_paths, pagerank\n",
    "from networkx.algorithms.components import connected_components\n",
    "from networkx.classes.function import density\n",
    "from networkx import convert\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import wilcoxon\n",
    "from tqdm import tqdm_notebook\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_name):\n",
    "    df = pd.read_csv(file_name, index_col=0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions to calculate feature values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Single-node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def node_degree(graph, isolates):\n",
    "    values = []\n",
    "    graph = convert.from_edgelist((literal_eval(graph)))\n",
    "    graph.add_nodes_from(literal_eval(isolates))\n",
    "    for g in networkx.connected_component_subgraphs(graph):\n",
    "        values.append(np.mean([degree for (node, degree) in list(g.degree())]))\n",
    "    return np.mean(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering_coef(graph, isolates):\n",
    "    graph = convert.from_edgelist((literal_eval(graph)))    \n",
    "    graph.add_nodes_from(literal_eval(isolates))\n",
    "    return np.mean(list(clustering(graph).values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def av_pagerank(graph, isolates):\n",
    "    graph = convert.from_edgelist((literal_eval(graph)))\n",
    "    graph.add_nodes_from(literal_eval(isolates))\n",
    "    return np.mean(list(pagerank(graph).values()))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Pairwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_distance_per_unit(graph, sentences, isolates): #second argument can be paragraphs or sentences\n",
    "    \n",
    "    values = []\n",
    "    sentences=(literal_eval(sentences.replace(\"{\",\"[\").replace(\"}\",\"]\").\n",
    "                            replace(\", set()\", \"\").replace(\"[set(), \", \"[\").replace(\", set()]\", \"]\")))\n",
    "        \n",
    "    graph = convert.from_edgelist((literal_eval(graph)))\n",
    "    graph.add_nodes_from(literal_eval(isolates))\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        subgraph = networkx.Graph()\n",
    "        subgraph.add_nodes_from([node for node in set(sentence)])\n",
    "        subgraph.add_edges_from([(node1,node2) for (node1,node2) in graph.edges() if node1 in subgraph.nodes() \n",
    "                                or node2 in subgraph.nodes()])\n",
    "        \n",
    "        for g in networkx.connected_component_subgraphs(subgraph):            \n",
    "            values.append((networkx.average_shortest_path_length(g)))\n",
    "            \n",
    "    return np.mean(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_semrel(graph, sentences, isolates, path_length=5, decay_factor=0.25): \n",
    "    #second argument can be paragraphs or sentences\n",
    "    #based on Hulpus et al. (2015)\n",
    "    \n",
    "    values = []\n",
    "    sentences=(literal_eval(sentences.replace(\"{\",\"[\").replace(\"}\",\"]\").\n",
    "                           replace(\", set()\", \"\").replace(\"[set(), \", \"[\").replace(\", set()]\", \"]\")))\n",
    "        \n",
    "    graph = convert.from_edgelist((literal_eval(graph)))\n",
    "    graph.add_nodes_from(literal_eval(isolates))\n",
    "\n",
    "    graph_prop = (graph.edges.data())\n",
    "\n",
    "    \n",
    "    \n",
    "    for sentence in (sentences):\n",
    "        \n",
    "        graph_relatedness = defaultdict(float)\n",
    "        exclusivities = defaultdict(float)\n",
    "        \n",
    "        subgraph = networkx.Graph()\n",
    "        subgraph.add_nodes_from([node for node in set(sentence)])\n",
    "        subgraph.add_edges_from([(node1,node2) for (node1,node2) in graph.edges() if node1 in subgraph.nodes() \n",
    "                                or node2 in subgraph.nodes()])\n",
    "\n",
    "        for (node1, node2) in subgraph.edges():   #two related nodes can have more properties connecting them\n",
    "                # for each property connecting two nodes\n",
    "                prop = [tup[2][\"prop\"] for tup in graph_prop if tup[0]==node1 and tup[1]==node2]\n",
    "                #their exclusivity depends on how many other edges bear the same property\n",
    "                if (len([tup for tup in graph_prop if (tup[0]==node1 or tup[1]==node1) and tup[2][\"prop\"] in prop]) +  \n",
    "                                   len([tup for tup in graph_prop if (tup[1]==node2 or tup[0]==node2) and tup[2][\"prop\"] in prop])) != 0: \n",
    "              \n",
    "                    exclusivity = 1 / (len([tup for tup in graph_prop if (tup[0]==node1 or tup[1]==node1) and tup[2][\"prop\"] in prop]) +  \n",
    "                                       len([tup for tup in graph_prop if (tup[1]==node2 or tup[0]==node2) and tup[2][\"prop\"] in prop]))  \n",
    "\n",
    "                    exclusivities[((node1,node2))] += exclusivity\n",
    "\n",
    "        for node1, node2 in (list(itertools.combinations(list(subgraph.nodes()), 2))): \n",
    "                #the relatedness is calculated for each pair of nodes\n",
    "                relatedness = 0                                                  \n",
    "                sum_of_exc = 0\n",
    "\n",
    "                paths = list(networkx.simple_paths.all_simple_paths(subgraph, node1, node2, path_length))\n",
    "                for path in paths:  #if there is a path of length at most path_lenght between them                \n",
    "                    for related_nodes in list(zip(path, path[1:])):   #we check all connecting edges                    \n",
    "                        sum_of_exc += exclusivities[(related_nodes[0], related_nodes[1])] \n",
    "\n",
    "                if sum_of_exc != 0:               \n",
    "                    weight = 1 /  sum_of_exc #weight is for a path                             \n",
    "                    length = (len(path))\n",
    "\n",
    "                    relatedness += (weight * decay_factor ** length) #relatedness is for node pair\n",
    "\n",
    "                graph_relatedness[(node1,node2)]=(relatedness)\n",
    "        \n",
    "        if (list(graph_relatedness.values())) != []:\n",
    "            values.append(np.mean(list(graph_relatedness.values())))\n",
    "        \n",
    "    return np.mean(values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_conncomp_per_unit(graph, sentences, isolates): #second argument can be paragraphs or sentences\n",
    "    \n",
    "    values = []\n",
    "    sentences=(literal_eval(sentences.replace(\"{\",\"[\").replace(\"}\",\"]\").\n",
    "                            replace(\", set()\", \"\").replace(\"[set(), \", \"[\").replace(\", set()]\", \"]\")))\n",
    "    graph = convert.from_edgelist((literal_eval(graph)))\n",
    "    graph.add_nodes_from(literal_eval(isolates))\n",
    "\n",
    "    \n",
    "    for sentence in (sentences):\n",
    "        subgraph = networkx.Graph()\n",
    "        subgraph.add_nodes_from([node for node in set(sentence)])\n",
    "        subgraph.add_edges_from([(node1,node2) for (node1,node2) in graph.edges() if node1 in subgraph.nodes() \n",
    "                                or node2 in subgraph.nodes()])\n",
    "        \n",
    "        values.append(len(list(connected_components(subgraph))))\n",
    "\n",
    "    return np.mean(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering_coef_per_unit(graph, sentences, isolates): ##second argument can be paragraphs or sentences\n",
    "    \n",
    "    values = []\n",
    "    sentences=(literal_eval(sentences.replace(\"{\",\"[\").replace(\"}\",\"]\").\n",
    "                            replace(\", set()\", \"\").replace(\"[set(), \", \"[\").replace(\", set()]\", \"]\")))\n",
    "    graph = convert.from_edgelist((literal_eval(graph)))\n",
    "    graph.add_nodes_from(literal_eval(isolates))\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        subgraph = networkx.Graph()\n",
    "        subgraph.add_nodes_from([node for node in set(sentence)])\n",
    "        subgraph.add_edges_from([(node1,node2) for (node1,node2) in graph.edges() if node1 in subgraph.nodes() \n",
    "                                or node2 in subgraph.nodes()])\n",
    "\n",
    "        for g in networkx.connected_component_subgraphs(subgraph):\n",
    "            values.append(len(list(clustering(g).values())))\n",
    "\n",
    "    return np.mean(values)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_density_per_unit(graph, sentences, isolates): #second argument can be paragraphs or sentences\n",
    "    \n",
    "    values = []\n",
    "    sentences=(literal_eval(sentences.replace(\"{\",\"[\").replace(\"}\",\"]\").\n",
    "                            replace(\", set()\", \"\").replace(\"[set(), \", \"[\").replace(\", set()]\", \"]\")))\n",
    "    graph = convert.from_edgelist((literal_eval(graph)))\n",
    "    graph.add_nodes_from(literal_eval(isolates))\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        subgraph = networkx.Graph()\n",
    "\n",
    "        subgraph.add_nodes_from([node for node in set(sentence)])\n",
    "        subgraph.add_edges_from([(node1,node2) for (node1,node2) in graph.edges() if node1 in subgraph.nodes() \n",
    "                                or node2 in subgraph.nodes()])\n",
    "        \n",
    "        values.append(density(subgraph))\n",
    "\n",
    "    return np.mean(values)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_density(graph, isolates):\n",
    "    graph = convert.from_edgelist((literal_eval(graph)))\n",
    "    graph.add_nodes_from(literal_eval(isolates))\n",
    "    return density(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"rgb(0,0,0);height: 15.0px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add feature values to DF:  Britannica demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_graph = load_data('csv/britannica_with_graphs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_features_to_df(df, name):\n",
    "    feat_list = ['node_degree', 'clustering_coef', 'av_pagerank', 'pairwise_distance_per_sent', \n",
    "             'graph_conncomp_per_sent', 'clustering_coef_per_sent', 'graph_density_per_sent', \n",
    "             'graph_density', 'graph_conncomp_per_para', 'clustering_coef_per_para', 'graph_density_per_para', \n",
    "             'pairwise_distance_per_para', 'pairwise_semrel_per_sent', 'pairwise_semrel_per_para']\n",
    "\n",
    "    for feat in feat_list:\n",
    "        df[feat] = float \n",
    "    \n",
    "    for ind, row in tqdm_notebook(df.iterrows()):\n",
    "    \n",
    "        df['node_degree'][ind] = node_degree(row['sel_graph'], row['isolates'])\n",
    "        df['clustering_coef'][ind] = clustering_coef(row['sel_graph'], row['isolates'])\n",
    "        df['av_pagerank'][ind] = av_pagerank(row['sel_graph'], row['isolates'])\n",
    "        \n",
    "        df['pairwise_distance_per_sent'][ind] = pairwise_distance_per_unit(row['sel_graph'], row[\"sentences\"], row['isolates'])\n",
    "        df['pairwise_distance_per_para'][ind] = pairwise_distance_per_unit(row['sel_graph'], row[\"paragraphs\"], row['isolates'])\n",
    "        \n",
    "        df['graph_conncomp_per_sent'][ind] = graph_conncomp_per_unit(row['sel_graph'], row[\"sentences\"], row['isolates'])\n",
    "        df['graph_conncomp_per_para'][ind] = graph_conncomp_per_unit(row['sel_graph'], row[\"paragraphs\"], row['isolates'])\n",
    "\n",
    "        df['clustering_coef_per_sent'][ind] = clustering_coef_per_unit(row['sel_graph'], row[\"sentences\"], row['isolates'])\n",
    "        df['clustering_coef_per_para'][ind] = clustering_coef_per_unit(row['sel_graph'], row[\"paragraphs\"], row['isolates'])\n",
    "\n",
    "        df['graph_density_per_sent'][ind] = graph_density_per_unit(row['sel_graph'], row[\"sentences\"], row['isolates'])\n",
    "        df['graph_density_per_para'][ind] = graph_density_per_unit(row['sel_graph'], row[\"paragraphs\"], row['isolates'])\n",
    "        \n",
    "        df['graph_density'][ind] = graph_density(row['sel_graph'], row['isolates'])\n",
    "        \n",
    "        df['pairwise_semrel_per_sent'][ind]=pairwise_semrel(row['sel_graph_data'], row[\"sentences\"], row['isolates'])\n",
    "        df['pairwise_semrel_per_para'][ind]=pairwise_semrel(row['sel_graph_data'], row[\"paragraphs\"], row['isolates'])\n",
    "    \n",
    "    df.to_csv(\"csv/\" + name + \"_with_features.csv\")\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17a6d208b3e54277bb475194bc7c42e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df = add_features_to_df(df_graph, 'britannica')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"rgb(0,0,0);height: 15.0px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show results: Britannica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in case levels are not in order\n",
    "#df.sort_values(['name', 'score'], ascending=[True, False], inplace=True)\n",
    "#df.reset_index(inplace=True)\n",
    "#df['level']=df.index%5\n",
    "#df.head()\n",
    "#df.to_csv('csv/newsela_with_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_data('csv/britannica_with_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>name</th>\n",
       "      <th>score</th>\n",
       "      <th>annotations</th>\n",
       "      <th>sentences</th>\n",
       "      <th>paragraphs</th>\n",
       "      <th>graph</th>\n",
       "      <th>sel_graph</th>\n",
       "      <th>isolates</th>\n",
       "      <th>sel_graph_data</th>\n",
       "      <th>...</th>\n",
       "      <th>graph_conncomp_per_sent</th>\n",
       "      <th>clustering_coef_per_sent</th>\n",
       "      <th>graph_density_per_sent</th>\n",
       "      <th>graph_density</th>\n",
       "      <th>graph_conncomp_per_para</th>\n",
       "      <th>clustering_coef_per_para</th>\n",
       "      <th>graph_density_per_para</th>\n",
       "      <th>pairwise_distance_per_para</th>\n",
       "      <th>pairwise_semrel_per_sent</th>\n",
       "      <th>pairwise_semrel_per_para</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>level</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>...</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>...</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>...</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       path  name  score  annotations  sentences  paragraphs  graph  \\\n",
       "level                                                                 \n",
       "0        59    59     59           59         59          59      0   \n",
       "1        59    59     59           59         59          59      0   \n",
       "2        59    59     59           59         59          59      0   \n",
       "\n",
       "       sel_graph  isolates  sel_graph_data  ...  graph_conncomp_per_sent  \\\n",
       "level                                       ...                            \n",
       "0             59        59              59  ...                       59   \n",
       "1             59        59              59  ...                       59   \n",
       "2             59        59              59  ...                       59   \n",
       "\n",
       "       clustering_coef_per_sent  graph_density_per_sent  graph_density  \\\n",
       "level                                                                    \n",
       "0                            59                      59             59   \n",
       "1                            59                      59             59   \n",
       "2                            59                      59             59   \n",
       "\n",
       "       graph_conncomp_per_para  clustering_coef_per_para  \\\n",
       "level                                                      \n",
       "0                           59                        59   \n",
       "1                           59                        59   \n",
       "2                           59                        59   \n",
       "\n",
       "       graph_density_per_para  pairwise_distance_per_para  \\\n",
       "level                                                       \n",
       "0                          59                          59   \n",
       "1                          59                          59   \n",
       "2                          59                          59   \n",
       "\n",
       "       pairwise_semrel_per_sent  pairwise_semrel_per_para  \n",
       "level                                                      \n",
       "0                            59                        59  \n",
       "1                            59                        59  \n",
       "2                            59                        59  \n",
       "\n",
       "[3 rows x 24 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('level').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feat in ['node_degree', 'clustering_coef', 'av_pagerank', 'pairwise_distance_per_sent', \n",
    "             'graph_conncomp_per_sent', 'clustering_coef_per_sent', 'graph_density_per_sent', \n",
    "             'graph_density', 'graph_conncomp_per_para', 'clustering_coef_per_para', 'graph_density_per_para', \n",
    "             'pairwise_distance_per_para', 'pairwise_semrel_per_sent', 'pairwise_semrel_per_para']:\n",
    "    \n",
    "        #convert to numeric for future operations\n",
    "        df[feat] = df[feat].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "path                           object\n",
       "name                           object\n",
       "score                          object\n",
       "level                           int64\n",
       "annotations                    object\n",
       "sentences                      object\n",
       "paragraphs                     object\n",
       "graph                         float64\n",
       "sel_graph                      object\n",
       "isolates                       object\n",
       "sel_graph_data                 object\n",
       "node_degree                   float64\n",
       "clustering_coef               float64\n",
       "av_pagerank                   float64\n",
       "pairwise_distance_per_sent    float64\n",
       "graph_conncomp_per_sent       float64\n",
       "clustering_coef_per_sent      float64\n",
       "graph_density_per_sent        float64\n",
       "graph_density                 float64\n",
       "graph_conncomp_per_para       float64\n",
       "clustering_coef_per_para      float64\n",
       "graph_density_per_para        float64\n",
       "pairwise_distance_per_para    float64\n",
       "pairwise_semrel_per_sent      float64\n",
       "pairwise_semrel_per_para      float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check if it worked\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Higher = simpler:\n",
    "* pagerank\n",
    "* node_degree\n",
    "* density\n",
    "* semrel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node_degree</th>\n",
       "      <th>graph_density_per_sent</th>\n",
       "      <th>graph_density_per_para</th>\n",
       "      <th>av_pagerank</th>\n",
       "      <th>graph_density</th>\n",
       "      <th>pairwise_semrel_per_sent</th>\n",
       "      <th>pairwise_semrel_per_para</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>level</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.524435</td>\n",
       "      <td>0.181135</td>\n",
       "      <td>0.078909</td>\n",
       "      <td>0.006019</td>\n",
       "      <td>0.020829</td>\n",
       "      <td>0.065031</td>\n",
       "      <td>0.034302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.502462</td>\n",
       "      <td>0.222466</td>\n",
       "      <td>0.080971</td>\n",
       "      <td>0.007857</td>\n",
       "      <td>0.025506</td>\n",
       "      <td>0.069240</td>\n",
       "      <td>0.034576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.652699</td>\n",
       "      <td>0.249132</td>\n",
       "      <td>0.143085</td>\n",
       "      <td>0.015344</td>\n",
       "      <td>0.048913</td>\n",
       "      <td>0.072682</td>\n",
       "      <td>0.037052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       node_degree  graph_density_per_sent  graph_density_per_para  \\\n",
       "level                                                                \n",
       "0         0.524435                0.181135                0.078909   \n",
       "1         0.502462                0.222466                0.080971   \n",
       "2         0.652699                0.249132                0.143085   \n",
       "\n",
       "       av_pagerank  graph_density  pairwise_semrel_per_sent  \\\n",
       "level                                                         \n",
       "0         0.006019       0.020829                  0.065031   \n",
       "1         0.007857       0.025506                  0.069240   \n",
       "2         0.015344       0.048913                  0.072682   \n",
       "\n",
       "       pairwise_semrel_per_para  \n",
       "level                            \n",
       "0                      0.034302  \n",
       "1                      0.034576  \n",
       "2                      0.037052  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#display average feature values where higher=simpler\n",
    "results = df.groupby('level')[['node_degree', 'graph_density_per_sent', 'graph_density_per_para',\n",
    "                               \"av_pagerank\", 'graph_density', 'pairwise_semrel_per_sent',\n",
    "                              'pairwise_semrel_per_para']].mean()\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node_degree\n",
      "   0  1   2  3  4\n",
      "0  0 -4  24  0  0\n",
      "1  0  0  29  0  0\n",
      "2  0  0   0  0  0\n",
      "3  0  0   0  0  0\n",
      "4  0  0   0  0  0\n",
      "\n",
      "\n",
      "graph_density_per_sent\n",
      "   0   1   2  3  4\n",
      "0  0  22  37  0  0\n",
      "1  0   0  11  0  0\n",
      "2  0   0   0  0  0\n",
      "3  0   0   0  0  0\n",
      "4  0   0   0  0  0\n",
      "\n",
      "\n",
      "graph_density_per_para\n",
      "   0  1   2  3  4\n",
      "0  0  2  81  0  0\n",
      "1  0  0  76  0  0\n",
      "2  0  0   0  0  0\n",
      "3  0  0   0  0  0\n",
      "4  0  0   0  0  0\n",
      "\n",
      "\n",
      "av_pagerank\n",
      "   0   1    2  3  4\n",
      "0  0  30  154  0  0\n",
      "1  0   0   95  0  0\n",
      "2  0   0    0  0  0\n",
      "3  0   0    0  0  0\n",
      "4  0   0    0  0  0\n",
      "\n",
      "\n",
      "graph_density\n",
      "   0   1    2  3  4\n",
      "0  0  22  134  0  0\n",
      "1  0   0   91  0  0\n",
      "2  0   0    0  0  0\n",
      "3  0   0    0  0  0\n",
      "4  0   0    0  0  0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#display changes in feature values where higher=simpler\n",
    "for feat in ['node_degree', 'graph_density_per_sent', 'graph_density_per_para', \"av_pagerank\",  'graph_density']:\n",
    "    \n",
    "    feat_df = pd.DataFrame(0, index=[0,1,2,3,4], columns=[0,1,2,3,4])\n",
    "    for ind,row in enumerate(results[feat]):\n",
    "        for compare_ind in range(len(results[feat])):\n",
    "            if compare_ind<=ind:\n",
    "                feat_df[ind][compare_ind] += (results[feat][ind]*100 / results[feat][compare_ind])-100\n",
    "    \n",
    "    print(feat)\n",
    "    print(feat_df.head())\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lower = simpler:\n",
    "* clustering_coef\n",
    "* pairwise distance\n",
    "* conncomp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clustering_coef</th>\n",
       "      <th>clustering_coef_per_sent</th>\n",
       "      <th>clustering_coef_per_para</th>\n",
       "      <th>pairwise_distance_per_sent</th>\n",
       "      <th>pairwise_distance_per_para</th>\n",
       "      <th>graph_conncomp_per_sent</th>\n",
       "      <th>graph_conncomp_per_para</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>level</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.119313</td>\n",
       "      <td>7.134127</td>\n",
       "      <td>7.766490</td>\n",
       "      <td>1.164052</td>\n",
       "      <td>1.072889</td>\n",
       "      <td>2.318567</td>\n",
       "      <td>6.409737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.110549</td>\n",
       "      <td>6.337198</td>\n",
       "      <td>6.826522</td>\n",
       "      <td>1.150274</td>\n",
       "      <td>1.076909</td>\n",
       "      <td>1.924071</td>\n",
       "      <td>5.073012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.115842</td>\n",
       "      <td>4.715268</td>\n",
       "      <td>5.010809</td>\n",
       "      <td>1.025489</td>\n",
       "      <td>0.998849</td>\n",
       "      <td>1.567241</td>\n",
       "      <td>3.437550</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       clustering_coef  clustering_coef_per_sent  clustering_coef_per_para  \\\n",
       "level                                                                        \n",
       "0             0.119313                  7.134127                  7.766490   \n",
       "1             0.110549                  6.337198                  6.826522   \n",
       "2             0.115842                  4.715268                  5.010809   \n",
       "\n",
       "       pairwise_distance_per_sent  pairwise_distance_per_para  \\\n",
       "level                                                           \n",
       "0                        1.164052                    1.072889   \n",
       "1                        1.150274                    1.076909   \n",
       "2                        1.025489                    0.998849   \n",
       "\n",
       "       graph_conncomp_per_sent  graph_conncomp_per_para  \n",
       "level                                                    \n",
       "0                     2.318567                 6.409737  \n",
       "1                     1.924071                 5.073012  \n",
       "2                     1.567241                 3.437550  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#display average values where lower=simpler\n",
    "df.groupby('level')[['clustering_coef', 'clustering_coef_per_sent', 'clustering_coef_per_para',\n",
    "                               'pairwise_distance_per_sent', 'pairwise_distance_per_para', \n",
    "                               'graph_conncomp_per_sent', 'graph_conncomp_per_para']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = df.groupby('level')[['clustering_coef', 'clustering_coef_per_sent', 'clustering_coef_per_para',\n",
    "                               'pairwise_distance_per_sent', 'pairwise_distance_per_para', \n",
    "                               'graph_conncomp_per_sent', 'graph_conncomp_per_para']].mean()\n",
    "results = results.sort_values('level', ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clustering_coef\n",
      "   0  1  2  3  4\n",
      "0  0  4 -2  0  0\n",
      "1  0  0 -7  0  0\n",
      "2  0  0  0  0  0\n",
      "3  0  0  0  0  0\n",
      "4  0  0  0  0  0\n",
      "\n",
      "\n",
      "clustering_coef_per_sent\n",
      "   0   1   2  3  4\n",
      "0  0 -25 -33  0  0\n",
      "1  0   0 -11  0  0\n",
      "2  0   0   0  0  0\n",
      "3  0   0   0  0  0\n",
      "4  0   0   0  0  0\n",
      "\n",
      "\n",
      "clustering_coef_per_para\n",
      "   0   1   2  3  4\n",
      "0  0 -26 -35  0  0\n",
      "1  0   0 -12  0  0\n",
      "2  0   0   0  0  0\n",
      "3  0   0   0  0  0\n",
      "4  0   0   0  0  0\n",
      "\n",
      "\n",
      "pairwise_distance_per_sent\n",
      "   0   1   2  3  4\n",
      "0  0 -10 -11  0  0\n",
      "1  0   0  -1  0  0\n",
      "2  0   0   0  0  0\n",
      "3  0   0   0  0  0\n",
      "4  0   0   0  0  0\n",
      "\n",
      "\n",
      "pairwise_distance_per_para\n",
      "   0  1  2  3  4\n",
      "0  0 -7 -6  0  0\n",
      "1  0  0  0  0  0\n",
      "2  0  0  0  0  0\n",
      "3  0  0  0  0  0\n",
      "4  0  0  0  0  0\n",
      "\n",
      "\n",
      "graph_conncomp_per_sent\n",
      "   0   1   2  3  4\n",
      "0  0 -18 -32  0  0\n",
      "1  0   0 -17  0  0\n",
      "2  0   0   0  0  0\n",
      "3  0   0   0  0  0\n",
      "4  0   0   0  0  0\n",
      "\n",
      "\n",
      "graph_conncomp_per_para\n",
      "   0   1   2  3  4\n",
      "0  0 -32 -46  0  0\n",
      "1  0   0 -20  0  0\n",
      "2  0   0   0  0  0\n",
      "3  0   0   0  0  0\n",
      "4  0   0   0  0  0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#display changes in feature values where lower=simpler\n",
    "for feat in ['clustering_coef', 'clustering_coef_per_sent', 'clustering_coef_per_para',\n",
    "                               'pairwise_distance_per_sent', 'pairwise_distance_per_para', \n",
    "                               'graph_conncomp_per_sent', 'graph_conncomp_per_para']:\n",
    "    \n",
    "    feat_df = pd.DataFrame(0, index=[0,1,2,3,4], columns=[0,1,2,3,4])\n",
    "    for ind,row in enumerate(results[feat]):\n",
    "        for compare_ind in range(len(results[feat])):\n",
    "             if compare_ind<=ind:\n",
    "                feat_df[ind][compare_ind] += (results[feat][compare_ind]*100 / results[feat][ind])-100\n",
    "\n",
    "    print(feat)\n",
    "    print(feat_df.head())\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"rgb(0,0,0);height: 15.0px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check which differences are statistically significant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Britannica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['node_degree', 'clustering_coef', 'av_pagerank', 'pairwise_distance_per_sent', \n",
    "             'graph_conncomp_per_sent', 'clustering_coef_per_sent', 'graph_density_per_sent', \n",
    "             'graph_density', 'graph_conncomp_per_para', 'clustering_coef_per_para', 'graph_density_per_para', \n",
    "             'pairwise_distance_per_para', 'pairwise_semrel_per_sent', 'pairwise_semrel_per_para']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistically_significant = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-values for feature:  node_degree\n",
      "kids vs. students:  0.01\n",
      "kids vs. scholars:  0.00\n",
      "student vs. scholars:  0.57\n",
      "\n",
      "\n",
      "p-values for feature:  clustering_coef\n",
      "kids vs. students:  0.58\n",
      "kids vs. scholars:  0.70\n",
      "student vs. scholars:  0.62\n",
      "\n",
      "\n",
      "p-values for feature:  av_pagerank\n",
      "kids vs. students:  0.00\n",
      "kids vs. scholars:  0.00\n",
      "student vs. scholars:  0.01\n",
      "\n",
      "\n",
      "p-values for feature:  pairwise_distance_per_sent\n",
      "kids vs. students:  0.00\n",
      "kids vs. scholars:  0.00\n",
      "student vs. scholars:  0.53\n",
      "\n",
      "\n",
      "p-values for feature:  graph_conncomp_per_sent\n",
      "kids vs. students:  0.00\n",
      "kids vs. scholars:  0.00\n",
      "student vs. scholars:  0.00\n",
      "\n",
      "\n",
      "p-values for feature:  clustering_coef_per_sent\n",
      "kids vs. students:  0.00\n",
      "kids vs. scholars:  0.00\n",
      "student vs. scholars:  0.03\n",
      "\n",
      "\n",
      "p-values for feature:  graph_density_per_sent\n",
      "kids vs. students:  0.02\n",
      "kids vs. scholars:  0.00\n",
      "student vs. scholars:  0.00\n",
      "\n",
      "\n",
      "p-values for feature:  graph_density\n",
      "kids vs. students:  0.00\n",
      "kids vs. scholars:  0.00\n",
      "student vs. scholars:  0.01\n",
      "\n",
      "\n",
      "p-values for feature:  graph_conncomp_per_para\n",
      "kids vs. students:  0.00\n",
      "kids vs. scholars:  0.00\n",
      "student vs. scholars:  0.00\n",
      "\n",
      "\n",
      "p-values for feature:  clustering_coef_per_para\n",
      "kids vs. students:  0.00\n",
      "kids vs. scholars:  0.00\n",
      "student vs. scholars:  0.01\n",
      "\n",
      "\n",
      "p-values for feature:  graph_density_per_para\n",
      "kids vs. students:  0.00\n",
      "kids vs. scholars:  0.00\n",
      "student vs. scholars:  0.02\n",
      "\n",
      "\n",
      "p-values for feature:  pairwise_distance_per_para\n",
      "kids vs. students:  0.04\n",
      "kids vs. scholars:  0.04\n",
      "student vs. scholars:  0.93\n",
      "\n",
      "\n",
      "p-values for feature:  pairwise_semrel_per_sent\n",
      "kids vs. students:  0.10\n",
      "kids vs. scholars:  0.05\n",
      "student vs. scholars:  0.18\n",
      "\n",
      "\n",
      "p-values for feature:  pairwise_semrel_per_para\n",
      "kids vs. students:  0.00\n",
      "kids vs. scholars:  0.01\n",
      "student vs. scholars:  0.72\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for feat in features:    \n",
    "    scholar = df[feat].loc[(df['level'] == 0)]\n",
    "    student = df[feat].loc[(df['level'] == 1)]\n",
    "    kid = df[feat].loc[(df['level'] == 2)]\n",
    "    \n",
    "    print(\"p-values for feature: \", feat)\n",
    "    print('kids vs. students: ', \"{0:.2f}\".format(wilcoxon(kid, student)[1]))\n",
    "    if wilcoxon(kid, student)[1] < 0.01: statistically_significant.append((feat, 'kid-student'))\n",
    "    print('kids vs. scholars: ',  \"{0:.2f}\".format(wilcoxon(kid, scholar)[1]))\n",
    "    if wilcoxon(kid, scholar)[1] < 0.01: statistically_significant.append((feat, 'kid-scholar'))\n",
    "    print('student vs. scholars: ', \"{0:.2f}\".format(wilcoxon(student, scholar)[1]))\n",
    "    if wilcoxon(student, scholar)[1] < 0.01: statistically_significant.append((feat, 'student-scholar'))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistically siginicant differences:\n",
      "Feature  node_degree  for pair  kid-student\n",
      "Feature  node_degree  for pair  kid-scholar\n",
      "Feature  av_pagerank  for pair  kid-student\n",
      "Feature  av_pagerank  for pair  kid-scholar\n",
      "Feature  av_pagerank  for pair  student-scholar\n",
      "Feature  pairwise_distance_per_sent  for pair  kid-student\n",
      "Feature  pairwise_distance_per_sent  for pair  kid-scholar\n",
      "Feature  graph_conncomp_per_sent  for pair  kid-student\n",
      "Feature  graph_conncomp_per_sent  for pair  kid-scholar\n",
      "Feature  graph_conncomp_per_sent  for pair  student-scholar\n",
      "Feature  clustering_coef_per_sent  for pair  kid-student\n",
      "Feature  clustering_coef_per_sent  for pair  kid-scholar\n",
      "Feature  graph_density_per_sent  for pair  kid-scholar\n",
      "Feature  graph_density_per_sent  for pair  student-scholar\n",
      "Feature  graph_density  for pair  kid-student\n",
      "Feature  graph_density  for pair  kid-scholar\n",
      "Feature  graph_conncomp_per_para  for pair  kid-student\n",
      "Feature  graph_conncomp_per_para  for pair  kid-scholar\n",
      "Feature  graph_conncomp_per_para  for pair  student-scholar\n",
      "Feature  clustering_coef_per_para  for pair  kid-student\n",
      "Feature  clustering_coef_per_para  for pair  kid-scholar\n",
      "Feature  graph_density_per_para  for pair  kid-student\n",
      "Feature  graph_density_per_para  for pair  kid-scholar\n",
      "Feature  pairwise_semrel_per_para  for pair  kid-student\n",
      "Feature  pairwise_semrel_per_para  for pair  kid-scholar\n"
     ]
    }
   ],
   "source": [
    "print(\"Statistically siginicant differences:\")\n",
    "for tup in statistically_significant:\n",
    "    print('Feature ', tup[0], ' for pair ', tup[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Newsela"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_data('csv/newsela_with_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['node_degree', 'clustering_coef', 'av_pagerank', 'pairwise_distance_per_sent', \n",
    "             'graph_conncomp_per_sent', 'clustering_coef_per_sent', 'graph_density_per_sent', \n",
    "             'pairwise_semrel_per_sent']\n",
    "\n",
    "\n",
    "statistically_significant = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-values for feature:  node_degree\n",
      "level0 vs.  level1 0.11\n",
      "p-values for feature:  node_degree\n",
      "level0 vs.  level2 0.00\n",
      "p-values for feature:  node_degree\n",
      "level0 vs.  level3 0.00\n",
      "p-values for feature:  node_degree\n",
      "level0 vs.  level4 0.00\n",
      "p-values for feature:  node_degree\n",
      "level1 vs.  level2 0.01\n",
      "p-values for feature:  node_degree\n",
      "level1 vs.  level3 0.01\n",
      "p-values for feature:  node_degree\n",
      "level1 vs.  level4 0.00\n",
      "p-values for feature:  node_degree\n",
      "level2 vs.  level3 0.05\n",
      "p-values for feature:  node_degree\n",
      "level2 vs.  level4 0.00\n",
      "p-values for feature:  node_degree\n",
      "level3 vs.  level4 0.00\n",
      "p-values for feature:  clustering_coef\n",
      "level0 vs.  level1 0.14\n",
      "p-values for feature:  clustering_coef\n",
      "level0 vs.  level2 0.92\n",
      "p-values for feature:  clustering_coef\n",
      "level0 vs.  level3 0.80\n",
      "p-values for feature:  clustering_coef\n",
      "level0 vs.  level4 0.66\n",
      "p-values for feature:  clustering_coef\n",
      "level1 vs.  level2 0.03\n",
      "p-values for feature:  clustering_coef\n",
      "level1 vs.  level3 0.04\n",
      "p-values for feature:  clustering_coef\n",
      "level1 vs.  level4 0.14\n",
      "p-values for feature:  clustering_coef\n",
      "level2 vs.  level3 0.46\n",
      "p-values for feature:  clustering_coef\n",
      "level2 vs.  level4 0.18\n",
      "p-values for feature:  clustering_coef\n",
      "level3 vs.  level4 0.19\n",
      "p-values for feature:  av_pagerank\n",
      "level0 vs.  level1 0.00\n",
      "p-values for feature:  av_pagerank\n",
      "level0 vs.  level2 0.00\n",
      "p-values for feature:  av_pagerank\n",
      "level0 vs.  level3 0.00\n",
      "p-values for feature:  av_pagerank\n",
      "level0 vs.  level4 0.00\n",
      "p-values for feature:  av_pagerank\n",
      "level1 vs.  level2 0.01\n",
      "p-values for feature:  av_pagerank\n",
      "level1 vs.  level3 0.00\n",
      "p-values for feature:  av_pagerank\n",
      "level1 vs.  level4 0.00\n",
      "p-values for feature:  av_pagerank\n",
      "level2 vs.  level3 0.00\n",
      "p-values for feature:  av_pagerank\n",
      "level2 vs.  level4 0.00\n",
      "p-values for feature:  av_pagerank\n",
      "level3 vs.  level4 0.00\n",
      "p-values for feature:  pairwise_distance_per_sent\n",
      "level0 vs.  level1 0.00\n",
      "p-values for feature:  pairwise_distance_per_sent\n",
      "level0 vs.  level2 0.27\n",
      "p-values for feature:  pairwise_distance_per_sent\n",
      "level0 vs.  level3 0.04\n",
      "p-values for feature:  pairwise_distance_per_sent\n",
      "level0 vs.  level4 0.00\n",
      "p-values for feature:  pairwise_distance_per_sent\n",
      "level1 vs.  level2 0.39\n",
      "p-values for feature:  pairwise_distance_per_sent\n",
      "level1 vs.  level3 0.16\n",
      "p-values for feature:  pairwise_distance_per_sent\n",
      "level1 vs.  level4 0.01\n",
      "p-values for feature:  pairwise_distance_per_sent\n",
      "level2 vs.  level3 0.06\n",
      "p-values for feature:  pairwise_distance_per_sent\n",
      "level2 vs.  level4 0.00\n",
      "p-values for feature:  pairwise_distance_per_sent\n",
      "level3 vs.  level4 0.00\n",
      "p-values for feature:  graph_conncomp_per_sent\n",
      "level0 vs.  level1 0.00\n",
      "p-values for feature:  graph_conncomp_per_sent\n",
      "level0 vs.  level2 0.00\n",
      "p-values for feature:  graph_conncomp_per_sent\n",
      "level0 vs.  level3 0.00\n",
      "p-values for feature:  graph_conncomp_per_sent\n",
      "level0 vs.  level4 0.00\n",
      "p-values for feature:  graph_conncomp_per_sent\n",
      "level1 vs.  level2 0.00\n",
      "p-values for feature:  graph_conncomp_per_sent\n",
      "level1 vs.  level3 0.00\n",
      "p-values for feature:  graph_conncomp_per_sent\n",
      "level1 vs.  level4 0.00\n",
      "p-values for feature:  graph_conncomp_per_sent\n",
      "level2 vs.  level3 0.00\n",
      "p-values for feature:  graph_conncomp_per_sent\n",
      "level2 vs.  level4 0.00\n",
      "p-values for feature:  graph_conncomp_per_sent\n",
      "level3 vs.  level4 0.00\n",
      "p-values for feature:  clustering_coef_per_sent\n",
      "level0 vs.  level1 0.02\n",
      "p-values for feature:  clustering_coef_per_sent\n",
      "level0 vs.  level2 0.12\n",
      "p-values for feature:  clustering_coef_per_sent\n",
      "level0 vs.  level3 0.08\n",
      "p-values for feature:  clustering_coef_per_sent\n",
      "level0 vs.  level4 0.00\n",
      "p-values for feature:  clustering_coef_per_sent\n",
      "level1 vs.  level2 0.61\n",
      "p-values for feature:  clustering_coef_per_sent\n",
      "level1 vs.  level3 0.21\n",
      "p-values for feature:  clustering_coef_per_sent\n",
      "level1 vs.  level4 0.00\n",
      "p-values for feature:  clustering_coef_per_sent\n",
      "level2 vs.  level3 0.40\n",
      "p-values for feature:  clustering_coef_per_sent\n",
      "level2 vs.  level4 0.00\n",
      "p-values for feature:  clustering_coef_per_sent\n",
      "level3 vs.  level4 0.00\n",
      "p-values for feature:  graph_density_per_sent\n",
      "level0 vs.  level1 0.00\n",
      "p-values for feature:  graph_density_per_sent\n",
      "level0 vs.  level2 0.00\n",
      "p-values for feature:  graph_density_per_sent\n",
      "level0 vs.  level3 0.00\n",
      "p-values for feature:  graph_density_per_sent\n",
      "level0 vs.  level4 0.00\n",
      "p-values for feature:  graph_density_per_sent\n",
      "level1 vs.  level2 0.00\n",
      "p-values for feature:  graph_density_per_sent\n",
      "level1 vs.  level3 0.00\n",
      "p-values for feature:  graph_density_per_sent\n",
      "level1 vs.  level4 0.00\n",
      "p-values for feature:  graph_density_per_sent\n",
      "level2 vs.  level3 0.00\n",
      "p-values for feature:  graph_density_per_sent\n",
      "level2 vs.  level4 0.00\n",
      "p-values for feature:  graph_density_per_sent\n",
      "level3 vs.  level4 0.00\n",
      "p-values for feature:  pairwise_semrel_per_sent\n",
      "level0 vs.  level1 0.05\n",
      "p-values for feature:  pairwise_semrel_per_sent\n",
      "level0 vs.  level2 0.00\n",
      "p-values for feature:  pairwise_semrel_per_sent\n",
      "level0 vs.  level3 0.00\n",
      "p-values for feature:  pairwise_semrel_per_sent\n",
      "level0 vs.  level4 0.00\n",
      "p-values for feature:  pairwise_semrel_per_sent\n",
      "level1 vs.  level2 0.06\n",
      "p-values for feature:  pairwise_semrel_per_sent\n",
      "level1 vs.  level3 0.00\n",
      "p-values for feature:  pairwise_semrel_per_sent\n",
      "level1 vs.  level4 0.00\n",
      "p-values for feature:  pairwise_semrel_per_sent\n",
      "level2 vs.  level3 0.00\n",
      "p-values for feature:  pairwise_semrel_per_sent\n",
      "level2 vs.  level4 0.00\n",
      "p-values for feature:  pairwise_semrel_per_sent\n",
      "level3 vs.  level4 0.08\n"
     ]
    }
   ],
   "source": [
    "for feat in features:\n",
    "    levels = {'level0' : df[feat].loc[(df['level'] == 0)],\n",
    "    'level1' : df[feat].loc[(df['level'] == 1)],\n",
    "    \"level2\" : df[feat].loc[(df['level'] == 2)],\n",
    "    'level3' : df[feat].loc[(df['level'] == 3)],\n",
    "    'level4' : df[feat].loc[(df['level'] == 4)]}\n",
    "        \n",
    "    for (levela, levelb) in itertools.combinations(levels, 2):\n",
    "        print(\"p-values for feature: \", feat)\n",
    "        print(str(levela) + ' vs. ', str(levelb), \"{0:.2f}\".format(wilcoxon(levels[levela], levels[levelb])[1]))\n",
    "        if wilcoxon(levels[levela], levels[levelb])[1] < 0.01: statistically_significant.append((feat, (levela,levelb)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistically siginicant differences:\n",
      "Feature  node_degree  for pair  ('level0', 'level2')\n",
      "Feature  node_degree  for pair  ('level0', 'level3')\n",
      "Feature  node_degree  for pair  ('level0', 'level4')\n",
      "Feature  node_degree  for pair  ('level1', 'level3')\n",
      "Feature  node_degree  for pair  ('level1', 'level4')\n",
      "Feature  node_degree  for pair  ('level2', 'level4')\n",
      "Feature  node_degree  for pair  ('level3', 'level4')\n",
      "Feature  av_pagerank  for pair  ('level0', 'level1')\n",
      "Feature  av_pagerank  for pair  ('level0', 'level2')\n",
      "Feature  av_pagerank  for pair  ('level0', 'level3')\n",
      "Feature  av_pagerank  for pair  ('level0', 'level4')\n",
      "Feature  av_pagerank  for pair  ('level1', 'level2')\n",
      "Feature  av_pagerank  for pair  ('level1', 'level3')\n",
      "Feature  av_pagerank  for pair  ('level1', 'level4')\n",
      "Feature  av_pagerank  for pair  ('level2', 'level3')\n",
      "Feature  av_pagerank  for pair  ('level2', 'level4')\n",
      "Feature  av_pagerank  for pair  ('level3', 'level4')\n",
      "Feature  pairwise_distance_per_sent  for pair  ('level0', 'level1')\n",
      "Feature  pairwise_distance_per_sent  for pair  ('level0', 'level4')\n",
      "Feature  pairwise_distance_per_sent  for pair  ('level1', 'level4')\n",
      "Feature  pairwise_distance_per_sent  for pair  ('level2', 'level4')\n",
      "Feature  pairwise_distance_per_sent  for pair  ('level3', 'level4')\n",
      "Feature  graph_conncomp_per_sent  for pair  ('level0', 'level1')\n",
      "Feature  graph_conncomp_per_sent  for pair  ('level0', 'level2')\n",
      "Feature  graph_conncomp_per_sent  for pair  ('level0', 'level3')\n",
      "Feature  graph_conncomp_per_sent  for pair  ('level0', 'level4')\n",
      "Feature  graph_conncomp_per_sent  for pair  ('level1', 'level2')\n",
      "Feature  graph_conncomp_per_sent  for pair  ('level1', 'level3')\n",
      "Feature  graph_conncomp_per_sent  for pair  ('level1', 'level4')\n",
      "Feature  graph_conncomp_per_sent  for pair  ('level2', 'level3')\n",
      "Feature  graph_conncomp_per_sent  for pair  ('level2', 'level4')\n",
      "Feature  graph_conncomp_per_sent  for pair  ('level3', 'level4')\n",
      "Feature  clustering_coef_per_sent  for pair  ('level0', 'level4')\n",
      "Feature  clustering_coef_per_sent  for pair  ('level1', 'level4')\n",
      "Feature  clustering_coef_per_sent  for pair  ('level2', 'level4')\n",
      "Feature  clustering_coef_per_sent  for pair  ('level3', 'level4')\n",
      "Feature  graph_density_per_sent  for pair  ('level0', 'level1')\n",
      "Feature  graph_density_per_sent  for pair  ('level0', 'level2')\n",
      "Feature  graph_density_per_sent  for pair  ('level0', 'level3')\n",
      "Feature  graph_density_per_sent  for pair  ('level0', 'level4')\n",
      "Feature  graph_density_per_sent  for pair  ('level1', 'level2')\n",
      "Feature  graph_density_per_sent  for pair  ('level1', 'level3')\n",
      "Feature  graph_density_per_sent  for pair  ('level1', 'level4')\n",
      "Feature  graph_density_per_sent  for pair  ('level2', 'level3')\n",
      "Feature  graph_density_per_sent  for pair  ('level2', 'level4')\n",
      "Feature  graph_density_per_sent  for pair  ('level3', 'level4')\n",
      "Feature  graph_density  for pair  ('level0', 'level1')\n",
      "Feature  graph_density  for pair  ('level0', 'level2')\n",
      "Feature  graph_density  for pair  ('level0', 'level3')\n",
      "Feature  graph_density  for pair  ('level0', 'level4')\n",
      "Feature  graph_density  for pair  ('level1', 'level2')\n",
      "Feature  graph_density  for pair  ('level1', 'level3')\n",
      "Feature  graph_density  for pair  ('level1', 'level4')\n",
      "Feature  graph_density  for pair  ('level2', 'level3')\n",
      "Feature  graph_density  for pair  ('level2', 'level4')\n",
      "Feature  graph_density  for pair  ('level3', 'level4')\n",
      "Feature  graph_conncomp_per_para  for pair  ('level0', 'level1')\n",
      "Feature  graph_conncomp_per_para  for pair  ('level0', 'level2')\n",
      "Feature  graph_conncomp_per_para  for pair  ('level0', 'level3')\n",
      "Feature  graph_conncomp_per_para  for pair  ('level0', 'level4')\n",
      "Feature  graph_conncomp_per_para  for pair  ('level1', 'level2')\n",
      "Feature  graph_conncomp_per_para  for pair  ('level1', 'level3')\n",
      "Feature  graph_conncomp_per_para  for pair  ('level1', 'level4')\n",
      "Feature  graph_conncomp_per_para  for pair  ('level2', 'level3')\n",
      "Feature  graph_conncomp_per_para  for pair  ('level2', 'level4')\n",
      "Feature  graph_conncomp_per_para  for pair  ('level3', 'level4')\n",
      "Feature  graph_density_per_para  for pair  ('level0', 'level1')\n",
      "Feature  graph_density_per_para  for pair  ('level0', 'level2')\n",
      "Feature  graph_density_per_para  for pair  ('level0', 'level3')\n",
      "Feature  graph_density_per_para  for pair  ('level0', 'level4')\n",
      "Feature  graph_density_per_para  for pair  ('level1', 'level2')\n",
      "Feature  graph_density_per_para  for pair  ('level1', 'level3')\n",
      "Feature  graph_density_per_para  for pair  ('level1', 'level4')\n",
      "Feature  graph_density_per_para  for pair  ('level2', 'level3')\n",
      "Feature  graph_density_per_para  for pair  ('level2', 'level4')\n",
      "Feature  graph_density_per_para  for pair  ('level3', 'level4')\n",
      "Feature  pairwise_distance_per_para  for pair  ('level0', 'level1')\n",
      "Feature  pairwise_semrel_per_sent  for pair  ('level0', 'level2')\n",
      "Feature  pairwise_semrel_per_sent  for pair  ('level0', 'level3')\n",
      "Feature  pairwise_semrel_per_sent  for pair  ('level0', 'level4')\n",
      "Feature  pairwise_semrel_per_sent  for pair  ('level1', 'level3')\n",
      "Feature  pairwise_semrel_per_sent  for pair  ('level1', 'level4')\n",
      "Feature  pairwise_semrel_per_sent  for pair  ('level2', 'level3')\n",
      "Feature  pairwise_semrel_per_sent  for pair  ('level2', 'level4')\n",
      "Feature  pairwise_semrel_per_para  for pair  ('level1', 'level4')\n",
      "Feature  pairwise_semrel_per_para  for pair  ('level2', 'level3')\n",
      "Feature  pairwise_semrel_per_para  for pair  ('level2', 'level4')\n",
      "Feature  pairwise_semrel_per_para  for pair  ('level3', 'level4')\n"
     ]
    }
   ],
   "source": [
    "print(\"Statistically siginicant differences:\")\n",
    "for tup in statistically_significant:\n",
    "    print('Feature ', tup[0], ' for pair ', tup[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"rgb(0,0,0);height: 15.0px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exclusivity-based semantic relatedness used for outlier removal\n",
    "* the clean_graph function is a modified version of pairwise_semrel that returns cleaned annotations\n",
    "* running the below cells adds a 'cleaned_anno' column to the DF\n",
    "* was tested on the first 45 texts of britannica\n",
    "* saved as britannica_semrel.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_graph(graph, isolates, path_length=5, decay_factor=0.25, threshold=0.00001): \n",
    "    #second argument can be paragraphs or sentences\n",
    "    #based on Hulpus et al. (2015)\n",
    "    \n",
    "    cleaned_annotations=[]\n",
    "    values = []\n",
    "        \n",
    "    graph = convert.from_edgelist((literal_eval(graph)))\n",
    "\n",
    "    graph_prop = (graph.edges.data())\n",
    "\n",
    "    graph_relatedness = defaultdict(list)\n",
    "           \n",
    "    exclusivities = defaultdict(float)\n",
    "        \n",
    "    for (node1, node2) in graph.edges():   #two related nodes can have more properties connecting them\n",
    "                # for each property connecting two nodes\n",
    "                prop = [tup[2][\"prop\"] for tup in graph_prop if tup[0]==node1 and tup[1]==node2]\n",
    "                #their exclusivity depends on how many other edges bear the same property\n",
    "                if (len([tup for tup in graph_prop if (tup[0]==node1 or tup[1]==node1) and tup[2][\"prop\"] in prop]) +  \n",
    "                                   len([tup for tup in graph_prop if (tup[1]==node2 or tup[0]==node2) and tup[2][\"prop\"] in prop])) != 0: \n",
    "              \n",
    "                    exclusivity = 1 / (len([tup for tup in graph_prop if (tup[0]==node1 or tup[1]==node1) and tup[2][\"prop\"] in prop]) +  \n",
    "                                       len([tup for tup in graph_prop if (tup[1]==node2 or tup[0]==node2) and tup[2][\"prop\"] in prop])-1)  \n",
    "                    #print(node1,node2,exclusivity)\n",
    "                    \n",
    "                    exclusivities[((node1,node2))] += exclusivity\n",
    "        \n",
    "    for node1, node2 in (list(itertools.combinations(list(graph.nodes()), 2))): \n",
    "                #the relatedness is calculated for each pair of nodes\n",
    "                relatedness = 0                                                  \n",
    "                sum_of_exc = 0\n",
    "\n",
    "                paths = list(networkx.simple_paths.all_simple_paths(graph, node1, node2, 5))\n",
    "                for path in paths:  #if there is a path of length at most path_lenght between them                \n",
    "                    for related_nodes in list(zip(path, path[1:])):   #we check all connecting edges                    \n",
    "                        sum_of_exc += exclusivities[(related_nodes[0], related_nodes[1])] \n",
    "\n",
    "                if sum_of_exc != 0:               \n",
    "                    weight = 1 /  (1/sum_of_exc) #weight is for a path                             \n",
    "                    length = (len(path))\n",
    "\n",
    "                    relatedness += (weight * decay_factor ** length) #relatedness is for node pair\n",
    "                  \n",
    "               # print(node1,node2,relatedness)\n",
    "                graph_relatedness[node1].append(relatedness)\n",
    "                graph_relatedness[node2].append(relatedness)\n",
    "  \n",
    "    #if (list(graph_relatedness.values())) != []:\n",
    "         #   values.append(np.mean(list(graph_relatedness.values())))\n",
    "    \n",
    "    for key in graph_relatedness:\n",
    "        if np.mean(graph_relatedness[key]) > threshold:\n",
    "                cleaned_annotations.append(key)  \n",
    "            \n",
    "    return cleaned_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_anno = []\n",
    "\n",
    "for ind,row in df[:45].iterrows():\n",
    "    print(ind)\n",
    "    g = df.iloc[ind]['sel_graph_data']\n",
    "    s = df.iloc[ind]['sentences']\n",
    "    i = df.iloc[ind]['isolates']   \n",
    "    cleaned_anno.append(clean_graph(g,s,i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cleaned_anno']=cleaned_anno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('csv/britannica_semrel.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
